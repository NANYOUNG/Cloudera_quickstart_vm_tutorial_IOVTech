<html>

<head>

  <title>Tutorial Exercise 4</title>

</head>

 <style>
   body { background-image : url("http://blogfiles.naver.net/20150201_187/drivesol_1422789780016gfVwj_PNG/wb3.png");
      background-position : 50% 50% ;
      background-attachment : fixed ;
      background-repeat : no-repeat; }
   </style>

<body>
<font face="Arial" size="5">
<b>Tutorial Exercise 4</b></font><br><br>


<font face="Arial" size="3">

Relationship strength analytics using Spark

<p>
You come up with a great idea that it would be interesting for the marketing team which 
products are most commonly purchased together. Perhaps there are optimizations to be made 
in marketing campaigns to position components together that will generate a strong 
lead pipeline? Perhaps they can use product correlation data to help up sales for the 
lesser viewed products? Or recover revenue for the product that was on the top 10 viewed, 
but not top 10 sold from last exercise?
The tool in CDH best suited for quick analytics on object relationships is Apache Spark. 
You can compose a Spark job to do this work and give you insight on product relationships.
</p>

<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">

spark-shell --jars /usr/lib/avro/avro-mapred.jar \
--conf spark.serializer=org.apache.spark.serializer.KryoSerializer
</td>
</tr></table>

image1</br>
image2</br>


Note: After a few seconds, you should see the spark shell. If you do not, you may need to hit the enter key.</br></br>

Once you have the scala> prompt, paste the following code, and hit enter.</br></br>



<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">

// First we're going to import the classes we need and open some of the files<br>
// we imported from our relational database into Hadoop with Sqoop
</td>
</tr></table>

<br><br>

<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">

import org.apache.avro.generic.GenericRecord
import org.apache.avro.mapred.{AvroInputFormat, AvroWrapper}
import org.apache.hadoop.io.NullWritable

val warehouse = "hdfs://quickstart.cloudera/user/hive/warehouse/"

val order_items_path = warehouse + "order_items"
val order_items = sc.hadoopFile[AvroWrapper[GenericRecord], NullWritable, AvroInputFormat[GenericRecord]](order_items_path)

val products_path = warehouse + "products"
val products = sc.hadoopFile[AvroWrapper[GenericRecord], NullWritable, AvroInputFormat[GenericRecord]](products_path)
</td>
</tr></table>



image3</br>
image4</br>
image5</br></br>

<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">


// Next, we extract the fields from order_items and products that we care about<br>
// and get a list of every product, its name and quantity, grouped by order
</td>
</tr></table>

<br><br>


<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">


val orders = order_items.map { x => (
    x._1.datum.get("order_item_product_id"),
    (x._1.datum.get("order_item_order_id"), x._1.datum.get("order_item_quantity")))
}.join(
  products.map { x => (
    x._1.datum.get("product_id"),
    (x._1.datum.get("product_name")))
  }
).map(x => (
    scala.Int.unbox(x._2._1._1), // order_id
    (
        scala.Int.unbox(x._2._1._2), // quantity
        x._2._2.toString // product_name
    )
)).groupByKey()
</td>
</tr></table>

<br><br>

image6</br></br>


<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">


// Finally, we tally how many times each combination of products appears<br>
// together in an order, and print the 10 most common combinations.


</td>


<br><br>

<table style="border: 0.28pt solid rgb(0, 0, 0); border-image: none; border-collapse: collapse; mso-table-overlap: never;">
<tr>
<td valign="top" style="background: rgb(242, 242, 242); padding: 1.41pt 5.1pt; border: 0.28pt solid rgb(0, 0, 0); border-image: none; width: 600pt;">


val cooccurrences = orders.map(order =>
  (
    order._1,
    order._2.toList.combinations(2).map(order_pair =>
        (
            if (order_pair(0)._2 < order_pair(1)._2) (order_pair(0)._2, order_pair(1)._2) else (order_pair(1)._2, order_pair(0)._2),
            order_pair(0)._1 * order_pair(1)._1
        )
    )
  )
)
val combos = cooccurrences.flatMap(x => x._2).reduceByKey((a, b) => a + b)
val mostCommon = combos.map(x => (x._2, x._1)).sortByKey(false).take(10)

println(mostCommon.deep.mkString("\n"))



</td>


<br><br>






* Note : You have to press "Enter" button at the end of command to execute.





<p>
To better understand this script, you could read through the comments which aim to explain 
what each block does and the basic process we're going through.</br></br>

When we do a 'map', we specify a function that will take each record and output a modified record. This is useful 
when we only need a couple of fields from each record or when we need the record to use a different field as the key: 
we simply invoke map with a function that takes in the entire record, and returns a new 
record with the fields and the key we want.</br></br>

The 'reduce' operations - like 'join' and 'groupBy' - 
will organize these records by their keys so we can group similar records together and then process 
them as a group. For instance, we group every purchased item by which specific order it was in - 
allowing us to determine all the combinations of products that were part of the same order.</br></br>

You should see a result similar to the following:</br>

image7</br></br></br>

CONCLUSION</br></br>

<p>
If it weren't for Spark, doing cooccurrence analysis like this would be an extremely 
arduous and time- consuming task. However, using Spark, and a few lines of scala, 
you were able to produce a list of the items most frequently purchased together in very little time.
</p>




</p>








</body>





</html>


