<html>


<head>

  <title>Tutorial Exercise 2</title>

</head>





<body>

Tutorial Exercise 2</br></br>

You'll use Hue. Hue is Graphical user interface for users of the cluster.

<p>
[image] ex2_1 <br>


<p>
Let's start Hue!
Click 'Fire Fox Icon'.
</p>

[image]ex2_2<br><p>

It¡¯s ¡®quickstart.cloudera¡¯ web page. <br>
Click ¡®Hue¡¯. <br>
Then Hue will be started.<br><br>

[image]ex2_3<br><p>

You'll use Hue to run some SQL queries against the data. <br>
Hue provides a web-based interface for many of the tools in CDH.<br><br>


[image]ex2_4<br><p>

In the QuickStart VM, the administrator username for Hue is 'cloudera' and the password is 'cloudera'.<p>

[image]ex2_5<br><p>

Once you are inside of Hue, click of Query Editors, and open the Impala Query Editor. <p>

[image]ex2_6<br><p>

You'll notice that the tables that we created in Hive are not available in Impala yet. <br>
This is because we created them outside of Impala, and Impala does not constantly check for changes to the table metadata. <p>

[image]ex2_7<br><p>

To get our tables to display, paste the following into the query editor and hit Execute.<p>

invalidate metadata <p>

[image]ex2_8<br><p>

"invalidate metadata" statement
: Marks the metadata for one or all tables as stale. Required after a table is created through the Hive shell, before the table is available for Impala queries. The next time the current Impala node performs a query against a table whose metadata is invalidated, Impala reloads the associated metadata before the query proceeds. This is a relatively expensive operation compared to the incremental metadata update done by the REFRESH statement, so in the common scenario of adding new data files to an existing table, prefer REFRESH rather than INVALIDATE METADATA. If you are not familiar with the way Impala uses metadata and how it shares the same metastore database as Hive, see Overview of Impala Metadata and the Metastore for background information.
<p>

Now, you click on the "Refresh Table List" icon.
<p>

[image]ex2_9<br><p>

You will see your new tables.<p>

[image]ex2_10<br><p>

Copy and paste or type in the following standard SQL example queries for calculating total revenue per product and showing the top 10 revenue generating products : 
<p>

-- Most popular product categories 
select c.category_name, count(order_item_quantity) as count 
from order_items oi 
inner join products p on oi.order_item_product_id = p.product_id 
inner join categories c on c.category_id = p.product_category_id 
group by c.category_name 
order by count desc 
limit 10;
<p>

Hit Execute. <p>

[image]ex2_11<br><p>

You should see results of the following form :<p>

[image]ex2_12<br><p>

Clear out the previous query. <p>

[image]ex2_13<br><p>

Copy and paste or type in the following standard SQL example queries : <p>

-- top 10 revenue generating products 
select p.product_id, p.product_name, r.revenue 
from products p inner join 
(select oi.order_item_product_id, sum(cast(oi.order_item_subtotal as float)) as revenue 
from order_items oi inner join orders o 
on oi.order_item_order_id = o.order_id 
where o.order_status <> 'CANCELED' 
and o.order_status <> 'SUSPECTED_FRAUD' 
group by order_item_product_id) r 
on p.product_id = r.order_item_product_id 
order by r.revenue desc 
limit 10;
<p>

[image]ex2_14<br><p>

You should see results similar to this : 
<p>

[image]ex2_15<br><p>
If one of these steps fails, please reach out to our Cloudera Live Forum and get help. Otherwise continue.
<p>

CONCLUSION <br>
Now you have learned how to query Hive tables using Impala and that you can use regular interfaces and tools (such as SQL) within a Hadoop environment as well. 
The idea here being that you can do the same reports you usually do, but where the architecture of Hadoop vs traditional systems provides much larger scale and flexibility.
<p>
</body>





</html>


